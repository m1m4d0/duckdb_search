"""
å¯¾è©±å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãƒ‡ãƒ¢

ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¯èµ·å‹•æ™‚ã®1å›ã®ã¿ã€‚
VSSï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰ã¨FTSï¼ˆå…¨æ–‡æ¤œç´¢ï¼‰ã‚’é¸æŠã—ã¦æ¤œç´¢ã§ãã¾ã™ã€‚
"""

import duckdb
import torch
import time

from embedding_model import get_model_and_tokenizer
from sentence_transformers import CrossEncoder

# è¨­å®š
DB_NAME = "duckdb_search"

print("=" * 80)
print("ğŸ“š ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  - å¯¾è©±ãƒ¢ãƒ¼ãƒ‰")
print("=" * 80)

# ãƒ¢ãƒ‡ãƒ«ã®å–å¾—ï¼ˆèµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘ï¼‰
print("\nğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
print("  â€» ã“ã®å‡¦ç†ã¯èµ·å‹•æ™‚ã®1å›ã®ã¿ã§ã™ï¼ˆã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ã«ç›¸å½“ï¼‰")
start_time = time.perf_counter()

# åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
v_model, v_tokenizer = get_model_and_tokenizer()

# Rerankingãƒ¢ãƒ‡ãƒ«
device = "cuda" if torch.cuda.is_available() else "cpu"
r_model = CrossEncoder(
    "hotchpotch/japanese-bge-reranker-v2-m3-v1", max_length=512, device=device
)

model_load_time = time.perf_counter() - start_time
print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {model_load_time:.3f}ç§’")
print("  - åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«: pfnet/plamo-embedding-1b")
print("  - Rerankingãƒ¢ãƒ‡ãƒ«: hotchpotch/japanese-bge-reranker-v2-m3-v1")
print("\n" + "=" * 80)
print("æº–å‚™å®Œäº†ï¼æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
print("ï¼ˆ'exit' ã¾ãŸã¯ 'quit' ã§çµ‚äº†ï¼‰")
print("=" * 80 + "\n")

# æ¥ç¶šãƒ—ãƒ¼ãƒ«ï¼ˆå†åˆ©ç”¨å¯èƒ½ãªæ¥ç¶šï¼‰
_conn = None


def get_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ï¼ˆå†åˆ©ç”¨ï¼‰"""
    global _conn
    if _conn is None:
        db_path = f"docs/db/{DB_NAME}.duckdb"
        try:
            # æ‹¡å¼µãŒæ—¢ã«å…¥ã£ã¦ã„ã‚‹å‰æã§èª­ã¿å–ã‚Šå°‚ç”¨æ¥ç¶š
            _conn = duckdb.connect(db_path, read_only=True)
            _conn.load_extension("vss")
            _conn.load_extension("fts")
        except Exception:
            # åˆå›ã ã‘æ›¸ãè¾¼ã¿å¯èƒ½ã«ã—ã¦æ‹¡å¼µã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€å†åº¦read-onlyã§é–‹ã
            install_conn = duckdb.connect(db_path)
            install_conn.install_extension("vss")
            install_conn.load_extension("vss")
            install_conn.install_extension("fts")
            install_conn.load_extension("fts")
            install_conn.close()

            _conn = duckdb.connect(db_path, read_only=True)
            _conn.load_extension("vss")
            _conn.load_extension("fts")
    return _conn


def vss_search(query, limit=5):
    """ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ"""
    total_start = time.perf_counter()

    conn = get_connection()

    with torch.inference_mode():
        # ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        embed_start = time.perf_counter()
        query_embedding = v_model.encode_query(query, v_tokenizer)
        embed_time = time.perf_counter() - embed_start

        # HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ©ç”¨ã—ãŸé«˜é€Ÿæ¤œç´¢
        search_start = time.perf_counter()
        rows = conn.sql(
            """
            SELECT
                id,
                array_cosine_distance(content_v, ?::FLOAT[2048]) as distance,
                document_name,
                document_path,
                category,
                tag,
                content
            FROM documents
            ORDER BY distance ASC
            LIMIT ?
            """,
            params=[query_embedding.cpu().squeeze().numpy().tolist(), limit],
        ).fetchall()
        search_time = time.perf_counter() - search_start

        total_time = time.perf_counter() - total_start

        return rows, {
            "embed_time": embed_time,
            "search_time": search_time,
            "total_time": total_time,
        }


def fts_search(keywords, limit=5):
    """å…¨æ–‡æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆBM25ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼‰"""
    total_start = time.perf_counter()

    conn = get_connection()

    # BM25æ¤œç´¢
    search_start = time.perf_counter()
    rows = conn.sql(
        """
        SELECT
            id,
            document_name,
            document_path,
            category,
            tag,
            content,
            content_fts,
            score
        FROM (
            SELECT *, fts_main_documents.match_bm25(id, ?) AS score
            FROM documents
        ) sq
        WHERE score IS NOT NULL
        ORDER BY score DESC
        LIMIT ?
        """,
        params=[keywords, limit],
    ).fetchall()
    search_time = time.perf_counter() - search_start

    total_time = time.perf_counter() - total_start

    return rows, {
        "search_time": search_time,
        "total_time": total_time,
    }


def display_vss_results(query, rows, timings):
    """VSSæ¤œç´¢çµæœã‚’è¡¨ç¤º"""
    print(f"\nğŸ” VSSæ¤œç´¢: '{query}'")
    print(
        f"â±ï¸  å‡¦ç†æ™‚é–“: {timings['total_time']:.3f}ç§’ "
        f"(åŸ‹ã‚è¾¼ã¿: {timings['embed_time']:.3f}ç§’, æ¤œç´¢: {timings['search_time']:.3f}ç§’)"
    )
    print("-" * 80)

    if not rows:
        print("âŒ çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    for idx, (
        id,
        distance,
        document_name,
        document_path,
        category,
        tag,
        content,
    ) in enumerate(rows, 1):
        similarity = 1 - distance  # cosine distance -> similarity
        print(f"\n[{idx}] ID: {id} | é¡ä¼¼åº¦: {similarity:.4f}")
        print(f"    ğŸ“„ {document_name} ({category})")

        # å†…å®¹ã‚’é©åˆ‡ãªé•·ã•ã§è¡¨ç¤º
        content_preview = content[:150].replace("\n", " ")
        if len(content) > 150:
            content_preview += "..."
        print(f"    ğŸ’¬ {content_preview}")


def display_fts_results(keywords, rows, timings):
    """FTSæ¤œç´¢çµæœã‚’è¡¨ç¤º"""
    print(f"\nğŸ” FTSæ¤œç´¢: '{keywords}'")
    print(f"â±ï¸  å‡¦ç†æ™‚é–“: {timings['total_time']:.3f}ç§’ (æ¤œç´¢: {timings['search_time']:.3f}ç§’)")
    print("-" * 80)

    if not rows:
        print("âŒ çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    for idx, (
        id,
        document_name,
        document_path,
        category,
        tag,
        content,
        content_fts,
        score,
    ) in enumerate(rows, 1):
        print(f"\n[{idx}] ID: {id} | BM25ã‚¹ã‚³ã‚¢: {score:.4f}")
        print(f"    ğŸ“„ {document_name} ({category})")
        if len(content_fts) > 80:
            print(f"    ğŸ·ï¸  FTSã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {content_fts[:80]}...")
        else:
            print(f"    ğŸ·ï¸  FTSã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {content_fts}")

        # å†…å®¹ã‚’é©åˆ‡ãªé•·ã•ã§è¡¨ç¤º
        content_preview = content[:150].replace("\n", " ")
        if len(content) > 150:
            content_preview += "..."
        print(f"    ğŸ’¬ {content_preview}")


def reranking(query, vss_rows, fts_rows):
    """
    VSSã¨FTSã®æ¤œç´¢çµæœã‚’CrossEncoderã§å†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        vss_rows: VSSæ¤œç´¢çµæœ
        fts_rows: FTSæ¤œç´¢çµæœ

    Returns:
        (reranked_rows, timings)
    """
    total_start = time.perf_counter()

    # çµæœã‚’ãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡æ’é™¤ï¼‰ - idã‚’ã‚­ãƒ¼ã«ã™ã‚‹ã“ã¨ã§è¡çªã‚’é˜²ã
    passages = {}  # {id: (document_name, document_path, category, tag, content)}

    # VSSã®çµæœã‚’è¿½åŠ 
    for row in vss_rows:
        id, _distance, document_name, _document_path, category, _tag, content = row
        passages[id] = (document_name, _document_path, category, _tag, content)

    # FTSã®çµæœã‚’è¿½åŠ ï¼ˆåŒã˜IDãŒã‚ã‚Œã°ä¸Šæ›¸ãï¼‰
    for row in fts_rows:
        id, document_name, _document_path, category, _tag, content, _content_fts, _score = row
        passages[id] = (document_name, _document_path, category, _tag, content)

    # CrossEncoderã§å†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    rerank_start = time.perf_counter()
    scores = r_model.predict([(query, passages[id][4]) for id in passages.keys()])
    rerank_time = time.perf_counter() - rerank_start

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    reranked = sorted(
        [
            (id, score, passages[id][0], passages[id][1], passages[id][2], passages[id][3], passages[id][4])
            for id, score in zip(passages.keys(), scores)
        ],
        key=lambda x: x[1],
        reverse=True,
    )

    total_time = time.perf_counter() - total_start

    return reranked, {
        "rerank_time": rerank_time,
        "total_time": total_time,
    }


def display_hybrid_results(query, rows, timings):
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢çµæœã‚’è¡¨ç¤º"""
    print(f"\nğŸ” ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆVSS + FTS + Rerankingï¼‰: '{query}'")
    print(
        f"â±ï¸  å‡¦ç†æ™‚é–“: {timings['total_time']:.3f}ç§’ "
        f"(Reranking: {timings['rerank_time']:.3f}ç§’)"
    )
    print("-" * 80)

    if not rows:
        print("âŒ çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    for idx, (id, score, document_name, document_path, category, tag, content) in enumerate(rows, 1):
        print(f"\n[{idx}] ID: {id} | Rerankã‚¹ã‚³ã‚¢: {score:.4f}")
        print(f"    ğŸ“„ {document_name} ({category})")

        # å†…å®¹ã‚’é©åˆ‡ãªé•·ã•ã§è¡¨ç¤º
        content_preview = content[:150].replace("\n", " ")
        if len(content) > 150:
            content_preview += "..."
        print(f"    ğŸ’¬ {content_preview}")


def close_connection():
    """æ¥ç¶šã‚’æ˜ç¤ºçš„ã«ã‚¯ãƒ­ãƒ¼ã‚º"""
    global _conn
    if _conn is not None:
        _conn.close()
        _conn = None


def main():
    """å¯¾è©±å‹æ¤œç´¢ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
    search_count = 0

    try:
        while True:
            # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰é¸æŠ
            print("\næ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
            print("  1: VSSï¼ˆãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ï¼‰")
            print("  2: FTSï¼ˆå…¨æ–‡æ¤œç´¢/BM25ï¼‰")
            print("  3: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼ˆVSS + FTS + Rerankingï¼‰")
            try:
                mode = input("ãƒ¢ãƒ¼ãƒ‰ (1/2/3)> ").strip()
            except EOFError:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if mode.lower() in ["exit", "quit", "q", "çµ‚äº†"]:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if mode not in ["1", "2", "3"]:
                print("âš ï¸  1, 2 ã¾ãŸã¯ 3 ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                continue

            # ã‚¯ã‚¨ãƒªå…¥åŠ›
            try:
                if mode == "1":
                    query = input("æ¤œç´¢ã‚¯ã‚¨ãƒª> ").strip()
                elif mode == "2":
                    query = input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰> ").strip()
                else:  # mode == "3"
                    query = input("æ¤œç´¢ã‚¯ã‚¨ãƒª> ").strip()
            except EOFError:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if query.lower() in ["exit", "quit", "q", "çµ‚äº†"]:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if not query:
                continue

            # æ¤œç´¢å®Ÿè¡Œ
            search_count += 1
            try:
                if mode == "1":
                    rows, timings = vss_search(query, limit=5)
                    display_vss_results(query, rows, timings)
                elif mode == "2":
                    rows, timings = fts_search(query, limit=5)
                    display_fts_results(query, rows, timings)
                else:  # mode == "3"
                    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢: VSS + FTS + Reranking
                    vss_rows, vss_timings = vss_search(query, limit=5)
                    fts_rows, fts_timings = fts_search(query, limit=5)
                    reranked, rerank_timings = reranking(query, vss_rows, fts_rows)

                    # ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’çµ±åˆ
                    combined_timings = {
                        "total_time": vss_timings["total_time"] + fts_timings["total_time"] + rerank_timings["total_time"],
                        "rerank_time": rerank_timings["rerank_time"],
                    }
                    display_hybrid_results(query, reranked[:5], combined_timings)
            except Exception as e:
                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Ctrl+C ã§çµ‚äº†ã—ã¾ã™")
    finally:
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        print("\n" + "=" * 80)
        print("ğŸ“Š çµ±è¨ˆæƒ…å ±")
        print(f"  ç·æ¤œç´¢å›æ•°: {search_count}å›")
        print(f"  ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰: 1å›ã®ã¿ ({model_load_time:.3f}ç§’)")
        print("=" * 80)

        # æ¥ç¶šã‚’ã‚¯ãƒ­ãƒ¼ã‚º
        close_connection()


if __name__ == "__main__":
    main()
