"""
å¯¾è©±å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãƒ‡ãƒ¢

ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¯èµ·å‹•æ™‚ã®1å›ã®ã¿ã€‚
VSSï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰ã¨FTSï¼ˆå…¨æ–‡æ¤œç´¢ï¼‰ã‚’é¸æŠã—ã¦æ¤œç´¢ã§ãã¾ã™ã€‚
"""

import duckdb
import torch
import time

from embedding_model import get_model_and_tokenizer

# è¨­å®š
DB_NAME = "duckdb_search"

print("=" * 80)
print("ğŸ“š ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  - å¯¾è©±ãƒ¢ãƒ¼ãƒ‰")
print("=" * 80)

# ãƒ¢ãƒ‡ãƒ«ã®å–å¾—ï¼ˆèµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘ï¼‰
print("\nğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
print("  â€» ã“ã®å‡¦ç†ã¯èµ·å‹•æ™‚ã®1å›ã®ã¿ã§ã™ï¼ˆã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ã«ç›¸å½“ï¼‰")
start_time = time.perf_counter()
v_model, v_tokenizer = get_model_and_tokenizer()
model_load_time = time.perf_counter() - start_time
print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {model_load_time:.3f}ç§’")
print("\n" + "=" * 80)
print("æº–å‚™å®Œäº†ï¼æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
print("ï¼ˆ'exit' ã¾ãŸã¯ 'quit' ã§çµ‚äº†ï¼‰")
print("=" * 80 + "\n")

# æ¥ç¶šãƒ—ãƒ¼ãƒ«ï¼ˆå†åˆ©ç”¨å¯èƒ½ãªæ¥ç¶šï¼‰
_conn = None


def get_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ï¼ˆå†åˆ©ç”¨ï¼‰"""
    global _conn
    if _conn is None:
        db_path = f"docs/db/{DB_NAME}.duckdb"
        _conn = duckdb.connect(db_path, read_only=True)
        _conn.install_extension("vss")
        _conn.load_extension("vss")
        _conn.install_extension("fts")
        _conn.load_extension("fts")
    return _conn


def vss_search(query, limit=5):
    """ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ"""
    total_start = time.perf_counter()

    conn = get_connection()

    with torch.inference_mode():
        # ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        embed_start = time.perf_counter()
        query_embedding = v_model.encode_query(query, v_tokenizer)
        embed_time = time.perf_counter() - embed_start

        # HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ©ç”¨ã—ãŸé«˜é€Ÿæ¤œç´¢
        search_start = time.perf_counter()
        rows = conn.sql(
            """
            SELECT
                id,
                array_cosine_distance(content_v, ?::FLOAT[2048]) as distance,
                document_name,
                document_path,
                category,
                tag,
                content
            FROM documents
            ORDER BY distance ASC
            LIMIT ?
            """,
            params=[query_embedding.cpu().squeeze().numpy().tolist(), limit],
        ).fetchall()
        search_time = time.perf_counter() - search_start

        total_time = time.perf_counter() - total_start

        return rows, {
            "embed_time": embed_time,
            "search_time": search_time,
            "total_time": total_time,
        }


def fts_search(keywords, limit=5):
    """å…¨æ–‡æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆBM25ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼‰"""
    total_start = time.perf_counter()

    conn = get_connection()

    # BM25æ¤œç´¢
    search_start = time.perf_counter()
    rows = conn.sql(
        """
        SELECT
            id,
            document_name,
            document_path,
            category,
            tag,
            content,
            content_fts,
            score
        FROM (
            SELECT *, fts_main_documents.match_bm25(id, ?) AS score
            FROM documents
        ) sq
        WHERE score IS NOT NULL
        ORDER BY score DESC
        LIMIT ?
        """,
        params=[keywords, limit],
    ).fetchall()
    search_time = time.perf_counter() - search_start

    total_time = time.perf_counter() - total_start

    return rows, {
        "search_time": search_time,
        "total_time": total_time,
    }


def display_vss_results(query, rows, timings):
    """VSSæ¤œç´¢çµæœã‚’è¡¨ç¤º"""
    print(f"\nğŸ” VSSæ¤œç´¢: '{query}'")
    print(
        f"â±ï¸  å‡¦ç†æ™‚é–“: {timings['total_time']:.3f}ç§’ "
        f"(åŸ‹ã‚è¾¼ã¿: {timings['embed_time']:.3f}ç§’, æ¤œç´¢: {timings['search_time']:.3f}ç§’)"
    )
    print("-" * 80)

    if not rows:
        print("âŒ çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    for idx, (
        id,
        distance,
        document_name,
        document_path,
        category,
        tag,
        content,
    ) in enumerate(rows, 1):
        similarity = 1 - distance  # cosine distance -> similarity
        print(f"\n[{idx}] ID: {id} | é¡ä¼¼åº¦: {similarity:.4f}")
        print(f"    ğŸ“„ {document_name} ({category})")

        # å†…å®¹ã‚’é©åˆ‡ãªé•·ã•ã§è¡¨ç¤º
        content_preview = content[:150].replace("\n", " ")
        if len(content) > 150:
            content_preview += "..."
        print(f"    ğŸ’¬ {content_preview}")


def display_fts_results(keywords, rows, timings):
    """FTSæ¤œç´¢çµæœã‚’è¡¨ç¤º"""
    print(f"\nğŸ” FTSæ¤œç´¢: '{keywords}'")
    print(f"â±ï¸  å‡¦ç†æ™‚é–“: {timings['total_time']:.3f}ç§’ (æ¤œç´¢: {timings['search_time']:.3f}ç§’)")
    print("-" * 80)

    if not rows:
        print("âŒ çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    for idx, (
        id,
        document_name,
        document_path,
        category,
        tag,
        content,
        content_fts,
        score,
    ) in enumerate(rows, 1):
        print(f"\n[{idx}] ID: {id} | BM25ã‚¹ã‚³ã‚¢: {score:.4f}")
        print(f"    ğŸ“„ {document_name} ({category})")
        if len(content_fts) > 80:
            print(f"    ğŸ·ï¸  FTSã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {content_fts[:80]}...")
        else:
            print(f"    ğŸ·ï¸  FTSã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {content_fts}")

        # å†…å®¹ã‚’é©åˆ‡ãªé•·ã•ã§è¡¨ç¤º
        content_preview = content[:150].replace("\n", " ")
        if len(content) > 150:
            content_preview += "..."
        print(f"    ğŸ’¬ {content_preview}")


def close_connection():
    """æ¥ç¶šã‚’æ˜ç¤ºçš„ã«ã‚¯ãƒ­ãƒ¼ã‚º"""
    global _conn
    if _conn is not None:
        _conn.close()
        _conn = None


def main():
    """å¯¾è©±å‹æ¤œç´¢ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
    search_count = 0

    try:
        while True:
            # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰é¸æŠ
            print("\næ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
            print("  1: VSSï¼ˆãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ï¼‰")
            print("  2: FTSï¼ˆå…¨æ–‡æ¤œç´¢/BM25ï¼‰")
            try:
                mode = input("ãƒ¢ãƒ¼ãƒ‰ (1/2)> ").strip()
            except EOFError:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if mode.lower() in ["exit", "quit", "q", "çµ‚äº†"]:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if mode not in ["1", "2"]:
                print("âš ï¸  1 ã¾ãŸã¯ 2 ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                continue

            # ã‚¯ã‚¨ãƒªå…¥åŠ›
            try:
                if mode == "1":
                    query = input("æ¤œç´¢ã‚¯ã‚¨ãƒª> ").strip()
                else:
                    query = input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰> ").strip()
            except EOFError:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if query.lower() in ["exit", "quit", "q", "çµ‚äº†"]:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break

            if not query:
                continue

            # æ¤œç´¢å®Ÿè¡Œ
            search_count += 1
            try:
                if mode == "1":
                    rows, timings = vss_search(query, limit=5)
                    display_vss_results(query, rows, timings)
                else:
                    rows, timings = fts_search(query, limit=5)
                    display_fts_results(query, rows, timings)
            except Exception as e:
                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Ctrl+C ã§çµ‚äº†ã—ã¾ã™")
    finally:
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        print("\n" + "=" * 80)
        print("ğŸ“Š çµ±è¨ˆæƒ…å ±")
        print(f"  ç·æ¤œç´¢å›æ•°: {search_count}å›")
        print(f"  ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰: 1å›ã®ã¿ ({model_load_time:.3f}ç§’)")
        print("=" * 80)

        # æ¥ç¶šã‚’ã‚¯ãƒ­ãƒ¼ã‚º
        close_connection()


if __name__ == "__main__":
    main()
